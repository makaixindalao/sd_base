#!/usr/bin/env python3
"""
GPUç‰ˆæœ¬PyTorchå®‰è£…è„šæœ¬
è‡ªåŠ¨æ£€æµ‹ç³»ç»Ÿç¯å¢ƒå¹¶å®‰è£…åˆé€‚çš„CUDAç‰ˆæœ¬PyTorch
"""

import sys
import subprocess
import platform

def print_step(message):
    """æ‰“å°æ­¥éª¤ä¿¡æ¯"""
    print(f"\n{'='*60}")
    print(f"ğŸ”§ {message}")
    print('='*60)

def print_info(message, success=None):
    """æ‰“å°ä¿¡æ¯"""
    if success is True:
        print(f"âœ… {message}")
    elif success is False:
        print(f"âŒ {message}")
    else:
        print(f"â„¹ï¸ {message}")

def check_nvidia_gpu():
    """æ£€æŸ¥NVIDIA GPUå’Œé©±åŠ¨"""
    print_step("æ£€æŸ¥NVIDIA GPUç¯å¢ƒ")
    
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            print_info("æ£€æµ‹åˆ°NVIDIA GPUé©±åŠ¨", True)
            
            # è§£æCUDAç‰ˆæœ¬
            lines = result.stdout.split('\n')
            cuda_version = None
            gpu_info = []
            
            for line in lines:
                if 'CUDA Version:' in line:
                    cuda_version = line.split('CUDA Version:')[1].strip().split()[0]
                elif 'GeForce' in line or 'RTX' in line or 'GTX' in line:
                    # æå–GPUä¿¡æ¯
                    parts = line.split('|')
                    if len(parts) >= 2:
                        gpu_name = parts[1].strip()
                        if gpu_name and ('GeForce' in gpu_name or 'RTX' in gpu_name or 'GTX' in gpu_name):
                            gpu_info.append(gpu_name)
            
            if cuda_version:
                print_info(f"ç³»ç»ŸCUDAç‰ˆæœ¬: {cuda_version}", True)
            
            for gpu in gpu_info:
                print_info(f"æ£€æµ‹åˆ°GPU: {gpu}", True)
                
            return True, cuda_version
        else:
            print_info("nvidia-smiå‘½ä»¤æ‰§è¡Œå¤±è´¥", False)
            return False, None
            
    except subprocess.TimeoutExpired:
        print_info("nvidia-smiå‘½ä»¤è¶…æ—¶", False)
        return False, None
    except FileNotFoundError:
        print_info("nvidia-smiå‘½ä»¤ä¸å­˜åœ¨ï¼Œå¯èƒ½æœªå®‰è£…NVIDIAé©±åŠ¨", False)
        return False, None
    except Exception as e:
        print_info(f"æ£€æŸ¥GPUæ—¶å‡ºé”™: {e}", False)
        return False, None

def check_current_pytorch():
    """æ£€æŸ¥å½“å‰PyTorchç‰ˆæœ¬"""
    print_step("æ£€æŸ¥å½“å‰PyTorchç‰ˆæœ¬")
    
    try:
        import torch
        version = torch.__version__
        cuda_available = torch.cuda.is_available()
        
        print_info(f"å½“å‰PyTorchç‰ˆæœ¬: {version}")
        print_info(f"CUDAæ”¯æŒ: {cuda_available}", cuda_available)
        
        if cuda_available:
            print_info(f"PyTorch CUDAç‰ˆæœ¬: {torch.version.cuda}")
            gpu_count = torch.cuda.device_count()
            print_info(f"å¯ç”¨GPUæ•°é‡: {gpu_count}")
            
        return True, cuda_available
        
    except ImportError:
        print_info("PyTorchæœªå®‰è£…", False)
        return False, False

def uninstall_pytorch():
    """å¸è½½ç°æœ‰PyTorch"""
    print_step("å¸è½½ç°æœ‰PyTorchç‰ˆæœ¬")
    
    packages_to_remove = ['torch', 'torchvision', 'torchaudio']
    
    for package in packages_to_remove:
        try:
            print_info(f"å¸è½½ {package}...")
            result = subprocess.run([
                sys.executable, '-m', 'pip', 'uninstall', package, '-y'
            ], capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0:
                print_info(f"{package} å¸è½½æˆåŠŸ", True)
            else:
                print_info(f"{package} å¸è½½å¤±è´¥æˆ–æœªå®‰è£…")
                
        except Exception as e:
            print_info(f"å¸è½½ {package} æ—¶å‡ºé”™: {e}", False)

def install_cuda_pytorch(cuda_version=None):
    """å®‰è£…CUDAç‰ˆæœ¬PyTorch"""
    print_step("å®‰è£…CUDAç‰ˆæœ¬PyTorch")
    
    # æ ¹æ®CUDAç‰ˆæœ¬é€‰æ‹©å®‰è£…URL
    if cuda_version and "12.1" in cuda_version:
        index_url = "https://download.pytorch.org/whl/cu121"
        print_info("é€‰æ‹©CUDA 12.1ç‰ˆæœ¬PyTorch")
    elif cuda_version and "11.8" in cuda_version:
        index_url = "https://download.pytorch.org/whl/cu118"
        print_info("é€‰æ‹©CUDA 11.8ç‰ˆæœ¬PyTorch")
    else:
        index_url = "https://download.pytorch.org/whl/cu121"
        print_info("ä½¿ç”¨é»˜è®¤CUDA 12.1ç‰ˆæœ¬PyTorch")
    
    # å®‰è£…å‘½ä»¤
    cmd = [
        sys.executable, '-m', 'pip', 'install',
        'torch', 'torchvision', 'torchaudio',
        '--index-url', index_url
    ]
    
    try:
        print_info("å¼€å§‹å®‰è£…CUDAç‰ˆæœ¬PyTorchï¼ˆå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...")
        print_info("å®‰è£…å‘½ä»¤: " + " ".join(cmd))
        
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=1800)
        
        if result.returncode == 0:
            print_info("CUDAç‰ˆæœ¬PyTorchå®‰è£…æˆåŠŸ", True)
            return True
        else:
            print_info("CUDAç‰ˆæœ¬PyTorchå®‰è£…å¤±è´¥", False)
            if result.stderr:
                print(f"é”™è¯¯ä¿¡æ¯: {result.stderr}")
            return False
            
    except subprocess.TimeoutExpired:
        print_info("å®‰è£…è¶…æ—¶", False)
        return False
    except Exception as e:
        print_info(f"å®‰è£…æ—¶å‡ºé”™: {e}", False)
        return False

def verify_installation():
    """éªŒè¯å®‰è£…ç»“æœ"""
    print_step("éªŒè¯å®‰è£…ç»“æœ")
    
    try:
        # é‡æ–°å¯¼å…¥torch
        if 'torch' in sys.modules:
            del sys.modules['torch']
        if 'torchvision' in sys.modules:
            del sys.modules['torchvision']
        if 'torchaudio' in sys.modules:
            del sys.modules['torchaudio']
            
        import torch
        
        version = torch.__version__
        cuda_available = torch.cuda.is_available()
        
        print_info(f"æ–°PyTorchç‰ˆæœ¬: {version}")
        print_info(f"CUDAæ”¯æŒ: {cuda_available}", cuda_available)
        
        if cuda_available:
            print_info(f"PyTorch CUDAç‰ˆæœ¬: {torch.version.cuda}")
            gpu_count = torch.cuda.device_count()
            print_info(f"å¯ç”¨GPUæ•°é‡: {gpu_count}")
            
            for i in range(gpu_count):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_props = torch.cuda.get_device_properties(i)
                gpu_memory_gb = gpu_props.total_memory / (1024**3)
                print_info(f"GPU {i}: {gpu_name} ({gpu_memory_gb:.1f}GB)")
                
            return True
        else:
            print_info("å®‰è£…å®Œæˆä½†CUDAä»ä¸å¯ç”¨ï¼Œå¯èƒ½éœ€è¦é‡å¯Pythonç¯å¢ƒ", False)
            return False
            
    except ImportError as e:
        print_info(f"éªŒè¯å¤±è´¥ï¼ŒPyTorchå¯¼å…¥é”™è¯¯: {e}", False)
        return False
    except Exception as e:
        print_info(f"éªŒè¯æ—¶å‡ºé”™: {e}", False)
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ GPUç‰ˆæœ¬PyTorchè‡ªåŠ¨å®‰è£…è„šæœ¬")
    print("=" * 60)
    
    # æ£€æŸ¥æ“ä½œç³»ç»Ÿ
    if platform.system() not in ['Windows', 'Linux']:
        print_info("æ­¤è„šæœ¬ä¸»è¦æ”¯æŒWindowså’ŒLinuxç³»ç»Ÿ", False)
        return 1
    
    # æ£€æŸ¥NVIDIA GPU
    has_gpu, cuda_version = check_nvidia_gpu()
    if not has_gpu:
        print_info("æœªæ£€æµ‹åˆ°NVIDIA GPUæˆ–é©±åŠ¨ï¼Œæ— æ³•å®‰è£…CUDAç‰ˆæœ¬PyTorch", False)
        print_info("è¯·å…ˆå®‰è£…NVIDIAé©±åŠ¨ç¨‹åºï¼Œæˆ–ç»§ç»­ä½¿ç”¨CPUç‰ˆæœ¬", False)
        return 1
    
    # æ£€æŸ¥å½“å‰PyTorch
    pytorch_installed, has_cuda = check_current_pytorch()
    
    if pytorch_installed and has_cuda:
        print_info("å½“å‰å·²å®‰è£…CUDAç‰ˆæœ¬PyTorchï¼Œæ— éœ€é‡æ–°å®‰è£…", True)
        return 0
    
    # ç¡®è®¤æ˜¯å¦ç»§ç»­
    if pytorch_installed:
        response = input("\næ˜¯å¦è¦å¸è½½å½“å‰PyTorchå¹¶å®‰è£…CUDAç‰ˆæœ¬ï¼Ÿ(y/N): ")
        if response.lower() not in ['y', 'yes']:
            print_info("ç”¨æˆ·å–æ¶ˆå®‰è£…")
            return 0
    
    # å¸è½½ç°æœ‰ç‰ˆæœ¬
    if pytorch_installed:
        uninstall_pytorch()
    
    # å®‰è£…CUDAç‰ˆæœ¬
    if not install_cuda_pytorch(cuda_version):
        print_info("å®‰è£…å¤±è´¥", False)
        return 1
    
    # éªŒè¯å®‰è£…
    if verify_installation():
        print_step("å®‰è£…å®Œæˆ")
        print_info("ğŸ‰ CUDAç‰ˆæœ¬PyTorchå®‰è£…æˆåŠŸï¼", True)
        print_info("ç°åœ¨å¯ä»¥ä½¿ç”¨GPUåŠ é€Ÿè¿›è¡ŒStable Diffusionå›¾ç‰‡ç”Ÿæˆ", True)
        print_info("å»ºè®®é‡å¯åº”ç”¨ç¨‹åºä»¥ç¡®ä¿æ–°é…ç½®ç”Ÿæ•ˆ", True)
        return 0
    else:
        print_info("å®‰è£…å¯èƒ½å­˜åœ¨é—®é¢˜ï¼Œå»ºè®®é‡å¯Pythonç¯å¢ƒåé‡è¯•", False)
        return 1

if __name__ == "__main__":
    try:
        exit_code = main()
        
        if exit_code == 0:
            print("\n" + "=" * 60)
            print("âœ… å®‰è£…å®Œæˆï¼è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤éªŒè¯é…ç½®ï¼š")
            print("python test_gpu_config.py")
            print("=" * 60)
        
        sys.exit(exit_code)
        
    except KeyboardInterrupt:
        print("\nâš ï¸ å®‰è£…è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ å®‰è£…è„šæœ¬å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
