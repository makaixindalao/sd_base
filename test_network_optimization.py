#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç½‘ç»œæ£€æŸ¥ä¼˜åŒ–æµ‹è¯•è„šæœ¬
æµ‹è¯•æ¨¡å‹åŠ è½½æ—¶çš„ç½‘ç»œæ£€æŸ¥é¡ºåºä¼˜åŒ–
"""

import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def test_network_check_optimization():
    """æµ‹è¯•ç½‘ç»œæ£€æŸ¥ä¼˜åŒ–"""
    print("=" * 60)
    print("ç½‘ç»œæ£€æŸ¥ä¼˜åŒ–æµ‹è¯•")
    print("=" * 60)
    
    try:
        from sd_generator import SDGenerator
        from config import config
        
        # åˆ›å»ºç”Ÿæˆå™¨å®ä¾‹
        generator = SDGenerator()
        
        # æµ‹è¯•åœºæ™¯1: æ¨¡å‹å·²åŠ è½½ï¼Œé‡å¤åŠ è½½åŒä¸€æ¨¡å‹
        print("\nğŸ“‹ æµ‹è¯•åœºæ™¯1: æ¨¡å‹å·²åŠ è½½æ—¶çš„é‡å¤åŠ è½½")
        print("-" * 40)
        
        # æ¨¡æ‹Ÿæ¨¡å‹å·²åŠ è½½çŠ¶æ€
        generator.model_loaded = True
        generator.current_model_name = "stabilityai/stable-diffusion-3.5-large"
        generator.pipeline = "mock_pipeline"  # æ¨¡æ‹Ÿpipelineå¯¹è±¡
        
        # å°è¯•åŠ è½½åŒä¸€æ¨¡å‹ï¼Œåº”è¯¥è·³è¿‡ç½‘ç»œæ£€æŸ¥
        print("å°è¯•é‡å¤åŠ è½½åŒä¸€æ¨¡å‹...")
        result = generator.load_model("stabilityai/stable-diffusion-3.5-large")
        
        if result:
            print("âœ… æµ‹è¯•é€šè¿‡: æˆåŠŸè·³è¿‡é‡å¤åŠ è½½")
        else:
            print("âŒ æµ‹è¯•å¤±è´¥: é‡å¤åŠ è½½æ£€æŸ¥å¤±è´¥")
        
        # æµ‹è¯•åœºæ™¯2: æœ¬åœ°æ¨¡å‹åŠ è½½
        print("\nğŸ“‹ æµ‹è¯•åœºæ™¯2: æœ¬åœ°æ¨¡å‹è·¯å¾„æ£€æµ‹")
        print("-" * 40)
        
        # é‡ç½®çŠ¶æ€
        generator.model_loaded = False
        generator.current_model_name = None
        generator.pipeline = None
        
        # æµ‹è¯•æœ¬åœ°æ¨¡å‹è·¯å¾„æ£€æµ‹
        local_paths = [
            "/path/to/model.safetensors",
            "C:\\models\\sd_model.safetensors",
            "./models/local_model",
            "models/stable-diffusion-v1-5"
        ]
        
        for path in local_paths:
            is_local = generator._is_local_model(path)
            print(f"è·¯å¾„: {path}")
            print(f"  æœ¬åœ°æ¨¡å‹: {'æ˜¯' if is_local else 'å¦'}")
        
        # æµ‹è¯•åœºæ™¯3: åœ¨çº¿æ¨¡å‹ç¼“å­˜æ£€æµ‹
        print("\nğŸ“‹ æµ‹è¯•åœºæ™¯3: åœ¨çº¿æ¨¡å‹ç¼“å­˜æ£€æµ‹")
        print("-" * 40)
        
        online_models = [
            "stabilityai/stable-diffusion-3.5-large",
            "runwayml/stable-diffusion-v1-5",
            "stabilityai/stable-diffusion-xl-base-1.0"
        ]
        
        for model in online_models:
            is_cached = generator._check_model_cached(model)
            print(f"æ¨¡å‹: {model}")
            print(f"  å·²ç¼“å­˜: {'æ˜¯' if is_cached else 'å¦'}")
        
        # æµ‹è¯•åœºæ™¯4: ç½‘ç»œæ£€æŸ¥æ–¹æ³•
        print("\nğŸ“‹ æµ‹è¯•åœºæ™¯4: ç½‘ç»œè¿æ¥æ£€æŸ¥")
        print("-" * 40)
        
        print("æµ‹è¯•ç½‘ç»œè¿æ¥...")
        network_available = generator._check_network_connection()
        print(f"ç½‘ç»œçŠ¶æ€: {'å¯ç”¨' if network_available else 'ä¸å¯ç”¨'}")
        
        print("\nâœ… ç½‘ç»œæ£€æŸ¥ä¼˜åŒ–æµ‹è¯•å®Œæˆ")
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
        print("è¯·ç¡®ä¿æ‰€æœ‰å¿…è¦çš„æ¨¡å—éƒ½å·²å®‰è£…")
        return False
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
        return False
    
    return True

def test_model_loading_scenarios():
    """æµ‹è¯•ä¸åŒçš„æ¨¡å‹åŠ è½½åœºæ™¯"""
    print("\n" + "=" * 60)
    print("æ¨¡å‹åŠ è½½åœºæ™¯æµ‹è¯•")
    print("=" * 60)
    
    try:
        from sd_generator import SDGenerator
        
        generator = SDGenerator()
        
        # åœºæ™¯1: é¦–æ¬¡åŠ è½½æ¨¡å‹
        print("\nğŸ“‹ åœºæ™¯1: é¦–æ¬¡åŠ è½½æ¨¡å‹")
        print("-" * 40)
        print("æ¨¡æ‹Ÿé¦–æ¬¡åŠ è½½åœ¨çº¿æ¨¡å‹çš„æµç¨‹...")
        
        # æ£€æŸ¥å½“å‰é…ç½®çš„æ¨¡å‹
        current_model = generator.generation_config.get("model", {}).get("name", "æœªé…ç½®")
        print(f"å½“å‰é…ç½®æ¨¡å‹: {current_model}")
        
        # åœºæ™¯2: åˆ‡æ¢æ¨¡å‹
        print("\nğŸ“‹ åœºæ™¯2: åˆ‡æ¢æ¨¡å‹")
        print("-" * 40)
        
        # æ¨¡æ‹Ÿå·²åŠ è½½ä¸€ä¸ªæ¨¡å‹
        generator.model_loaded = True
        generator.current_model_name = "model_a"
        
        # å°è¯•åŠ è½½ä¸åŒçš„æ¨¡å‹
        print("å½“å‰æ¨¡å‹: model_a")
        print("å°è¯•åˆ‡æ¢åˆ°: model_b")
        
        # è¿™åº”è¯¥ä¼šè§¦å‘æ–°çš„åŠ è½½æµç¨‹
        generator.current_model_name = "model_b"
        print("æ¨¡å‹åˆ‡æ¢æ£€æµ‹: éœ€è¦é‡æ–°åŠ è½½")
        
        # åœºæ™¯3: æ¨¡å‹å¸è½½åé‡æ–°åŠ è½½
        print("\nğŸ“‹ åœºæ™¯3: æ¨¡å‹å¸è½½åé‡æ–°åŠ è½½")
        print("-" * 40)
        
        print("å¸è½½å½“å‰æ¨¡å‹...")
        generator.unload_model()
        print(f"æ¨¡å‹çŠ¶æ€: å·²åŠ è½½={generator.model_loaded}, å½“å‰æ¨¡å‹={generator.current_model_name}")
        
        print("âœ… æ¨¡å‹åŠ è½½åœºæ™¯æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ åœºæ™¯æµ‹è¯•å¼‚å¸¸: {e}")
        return False
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨ç½‘ç»œæ£€æŸ¥ä¼˜åŒ–æµ‹è¯•")
    
    # è¿è¡Œæµ‹è¯•
    test1_result = test_network_check_optimization()
    test2_result = test_model_loading_scenarios()
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    if test1_result and test2_result:
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡")
        print("\nğŸ‰ ç½‘ç»œæ£€æŸ¥ä¼˜åŒ–åŠŸèƒ½æ­£å¸¸å·¥ä½œ:")
        print("  â€¢ æ¨¡å‹å·²åŠ è½½æ—¶è·³è¿‡é‡å¤åŠ è½½")
        print("  â€¢ æœ¬åœ°æ¨¡å‹è·³è¿‡ç½‘ç»œæ£€æŸ¥")
        print("  â€¢ ç¼“å­˜æ¨¡å‹ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ–‡ä»¶")
        print("  â€¢ åªåœ¨å¿…è¦æ—¶è¿›è¡Œç½‘ç»œæ£€æŸ¥")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
        print("è¯·æ£€æŸ¥ä»£ç ä¿®æ”¹æ˜¯å¦æ­£ç¡®")
    
    return test1_result and test2_result

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 